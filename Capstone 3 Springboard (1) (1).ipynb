{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying disaster tweets using NLP methods \n",
    "\n",
    "Notebook: http://localhost:8889/notebooks/Downloads/NLP%20(Whole%20Project)_%20Final.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task of this peroject is to let the machine learn to predict efficiently the nature of the tweet either disastrous or not. Hence, in this project, I have performed the following:\n",
    "\n",
    "1. Download and explore the Kaggle dataset. <br>\n",
    "2. Perform data wrangling on the data. <br>\n",
    "3. Perform data preprocessing and get data ready for modeling. <br>\n",
    "4. Building the classifier to detect if a tweet has disaster topics in it. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Data Wrangling section, I investigate missing values. I don't find missing values in Id, text and target columns. However, 33% of location values are missing and 0.007% values are missing in keywords. Hence, I drop 'location' variable as it contains more than 30% missing values. I also check for duplicates in our data and drop any duplicates present.  While checking for target balance, I find that the total number of samples in Target Class 1 is 4673 while in Target Class 0, it is about 6203. We can overcome the target imbalance using downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I firstly, tackle the target imbalance by downsampling with a 50:50 ratio. Thereafter, I clean the tweet text by the following:\n",
    "\n",
    "1. removing links \n",
    "2. removing any non-alphabetical characters, \n",
    "3. converting mentions to a word token\n",
    "4. converting retweets to a word token\n",
    "5. converting hashtags to a word token\n",
    "6. converting numeric values to a word token\n",
    "7. removing teh stop words\n",
    "\n",
    "I also analyzed the top 50 common words, looked at the graph and removed the most common words from the tweet text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Modelling section, I first split the data specifying x to be the input variable and y to be the output/dependent variable. Afterwards, I perform vectorization on x variable where vectorization means the process of converting words into numbers. Finally, I perform the train and test split of 90:10. \n",
    "\n",
    "I build different classifier models namely,\n",
    "\n",
    "1. Logistic Regression        \n",
    "2. Random Forest              \n",
    "3. KNN  \n",
    "4. Decision Tress             \n",
    "5. SVM                        \n",
    "6. Naive Bayes                \n",
    "7. XGBoost                   \n",
    "8. CatBoost  \n",
    "\n",
    "I also check the performance of each model based on the following metrics:\n",
    "\n",
    "1. Precision\n",
    "2. Recall\n",
    "3. F1 score\n",
    "4. Accuracy\n",
    "5. AUC for both train and test.\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my data is balanced (50:50), I primarily focus on F1 score and Accuracy score metric to determine which is the best model in predicting disaster tweets. Both Logistic Regression model and Naive Bayes looks like a good model as they have similar F1 score of 0.78. \n",
    "\n",
    "Logistic Regression model has slightly better Accuracy score (Acccuracy= 0.8) than the Naive Bayes model (Acccuracy= 0.79). \n",
    "\n",
    "However, while comparing the Logistic Regression Model and Naive Bayes model, I also now look at the model with a relatively lower \"AUC score difference\" between training and test set to minimize overfitting. I find that Logistic Regression model performs better as the difference between the AUC train and Auc test scores are relatively lower compared to Naive Bayes.\n",
    "\n",
    "Henceforth, I conclude that Logistic Regression model is a better model in this task to predict if a tweet has disaster topics in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
